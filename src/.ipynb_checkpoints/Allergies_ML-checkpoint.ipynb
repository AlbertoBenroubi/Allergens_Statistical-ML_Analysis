{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and Data Analysis on Data with allergen concentration measures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will try to construct a features-labels dataset from our initial data, in order to try some ML and Data Analysis techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data we have is in csv format and we created a script to load them (load_data.py). We have data from 2016 and 2017 in different files, so we need to put them together. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attributes: 43\n",
      "\n",
      "Number of samples: 731\n",
      "\n",
      "Headers: \n",
      "['DayCode' 'DayDate' 'Acer' 'Alnus' 'Ambrosia' 'Apiaceae' 'Artemisia'\n",
      " 'Betula' 'Cannabaceae' 'Carpinus' 'Castanea' 'Chenopodiaceae'\n",
      " 'Cichorioideae' 'Corylus' 'Cupressaceae' 'Cyperaceae' 'Ericaceae'\n",
      " 'Fabaceae' 'Fagus' 'Fraxinus' 'Juglans' 'Ligustrum' 'Liquidambar'\n",
      " 'Moraceae' 'Myricaceae' 'Myrtaceae' 'Olea' 'other Asteroideae'\n",
      " 'other Oleaceae' 'Papaveraceae' 'Pinaceae' 'Plantago' 'Platanus' 'Poaceae'\n",
      " 'Populus' 'Quercus' 'Rosaceae' 'Rumex' 'Salix' 'Thalictrum' 'Tilia'\n",
      " 'Ulmus' 'Urticaceae']\n",
      "\n",
      "\n",
      "Example data before removing the first 2 columns: \n",
      "[['151' 'May 30' '0' '0' '0' '0' '0' '0' '0,9920634921' '0' '0' '0' '0' '0'\n",
      "  '0,9920634921' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0,9920634921'\n",
      "  '0' '0' '0' '45,6349206349' '2,9761904762' '0' '10,4166666667' '0'\n",
      "  '14,880952381' '0' '0,496031746' '0' '2,4801587302' '0' '0'\n",
      "  '4,4642857143']\n",
      " ['152' 'May 31' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      "  '1,4880952381' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      "  '0,496031746' '0' '0' '29,2658730159' '1,9841269841' '0' '2,4801587302'\n",
      "  '0' '4,4642857143' '0' '0' '0' '0' '0' '0' '2,4801587302']\n",
      " ['153' 'Jun 01' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0,496031746' '0' '0'\n",
      "  '0' '0,496031746' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      "  '10,9126984127' '3,9682539683' '0' '14,880952381' '0' '0,9920634921' '0'\n",
      "  '3,9682539683' '0' '0' '0' '0' '10,9126984127']\n",
      " ['154' 'Jun 02' '0' '0' '0' '0,496031746' '0' '0' '3,4722222222' '0' '0'\n",
      "  '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      "  '0' '8,9285714286' '2,4801587302' '0,496031746' '3,9682539683' '0'\n",
      "  '1,9841269841' '0' '4,4642857143' '0' '0' '0' '0' '6,4484126984']\n",
      " ['155' 'Jun 03' '0' '0' '0' '0' '0' '0' '1,9841269841' '0,496031746' '0'\n",
      "  '0' '0' '0' '0,9920634921' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      "  '0' '0,496031746' '0' '0' '1,9841269841' '0' '0' '1,9841269841' '0'\n",
      "  '0,9920634921' '0' '0,496031746' '0' '0' '0' '0' '0,9920634921']]\n"
     ]
    }
   ],
   "source": [
    "import load_data\n",
    "import numpy as np\n",
    "\n",
    "headers, data1 = load_data.get_POLLEN_2016()\n",
    "_, data2 = load_data.get_POLLEN_2017()\n",
    "\n",
    "headers, data1, data2 = np.asarray(headers), np.asarray(data1), np.asarray(data2)\n",
    "\n",
    "n_attributes = headers.shape[0]\n",
    "\n",
    "total_data = np.concatenate((data1, data2))\n",
    "\n",
    "n_samples = total_data.shape[0]\n",
    "\n",
    "\n",
    "print 'Number of attributes: ' + str(n_attributes) +'\\n'\n",
    "\n",
    "print 'Number of samples: ' + str(n_samples) +'\\n'\n",
    "\n",
    "\n",
    "print 'Headers: ' \n",
    "print headers\n",
    "\n",
    "print '\\n'\n",
    "\n",
    "print 'Example data before removing the first 2 columns: ' \n",
    "print total_data[150:155,:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first 2 columns of the data are the id and the date of the measurement. We will remove the first and second column from the data and we will keep as a seperate matrix the second column, which has the specific day and month of the measurement: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_no_dates = total_data[:,2:]\n",
    "dates = total_data[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next step is to decide which the labels will be. We can think that allergies vary according to months of the year, so for our first try, we will have each month as a label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_nums=[1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "months_text=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "\n",
    "months_labels = []\n",
    "\n",
    "for date in dates:\n",
    "\n",
    "    for i in range(12):\n",
    "        if months_text[i] in date:\n",
    "            months_labels.append(months_nums[i])\n",
    "\n",
    "months_labels = np.asarray(months_labels)\n",
    "\n",
    "months_labels = months_labels.reshape((months_labels.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
